# Handling Missing Data in Pandas (15 mins)
## Lecture Materials with Exercises

### Introduction (2 minutes)

**Slide 1: The Reality of Missing Data**
- Missing data is ubiquitous in real-world datasets
- Pandas represents missing values as `NaN` (Not a Number)
- Proper handling of missing values is critical for accurate analysis
- Different strategies exist depending on the context and data

**Talking Points:**
- "In the real world, almost no dataset is perfectly complete. Missing data is the rule, not the exception."
- "Pandas gives us powerful tools to detect, handle, and sometimes recover missing values."
- "The strategy you choose for handling missing data can significantly impact your analysis results."
- "There's no one-size-fits-all approach - the right strategy depends on why the data is missing and what you're trying to analyze."

---

### 1. Detecting Missing Values (4 minutes)

**Slide 2: Methods for Finding Missing Data**

| Method | Returns | Purpose |
|--------|---------|---------|
| `isna()` / `isnull()` | Boolean mask (True where missing) | Identify missing values |
| `notna()` / `notnull()` | Boolean mask (True where not missing) | Identify non-missing values |
| `isna().sum()` | Count of missing values per column | Quantify missing data |
| `isna().any()` | Whether any value is missing per column | Quickly check for presence of missing data |
| `isna().all()` | Whether all values are missing per column | Check for completely empty columns |

**Code Example 1: Creating and Detecting Missing Values**
```python
import pandas as pd
import numpy as np

# Create a DataFrame with different types of missing values
data = {
    'A': [1, 2, np.nan, 4, 5],
    'B': [6, np.nan, 8, 9, np.nan],
    'C': [10, 11, 12, np.nan, 14],
    'D': [np.nan, np.nan, np.nan, np.nan, np.nan],
    'E': ['a', 'b', None, 'd', 'e']  # None also represents missing value
}
df = pd.DataFrame(data)
print("DataFrame with missing values:")
print(df)

# 1. Detect missing values with isna()
print("\n1. Boolean mask of missing values (isna):")
print(df.isna())  # True where values are missing

# 2. Detect non-missing values with notna()
print("\n2. Boolean mask of non-missing values (notna):")
print(df.notna())  # True where values are present

# 3. Count missing values per column
print("\n3. Count of missing values per column:")
print(df.isna().sum())

# 4. Check if any value in each column is missing
print("\n4. Are there any missing values in each column?")
print(df.isna().any())

# 5. Check if entire column is missing
print("\n5. Are all values missing in each column?")
print(df.isna().all())

# 6. Count total missing values in DataFrame
total_missing = df.isna().sum().sum()
print(f"\n6. Total missing values in DataFrame: {total_missing}")
```

**Code Example 2: Using Boolean Masks to Filter Data**
```python
# 1. Filter rows with missing values in column 'A'
rows_with_missing_A = df[df['A'].isna()]
print("1. Rows with missing values in column A:")
print(rows_with_missing_A)

# 2. Filter rows with any missing value
rows_with_any_missing = df[df.isna().any(axis=1)]
print("\n2. Rows with any missing value:")
print(rows_with_any_missing)

# 3. Filter rows with no missing values
complete_rows = df[df.notna().all(axis=1)]
print("\n3. Rows with no missing values:")
print(complete_rows)

# 4. Check if specific cells are missing
print("\n4. Is value at row 2, column A missing?")
print(pd.isna(df.at[2, 'A']))  # True
```

**Talking Points:**
- "Pandas provides a consistent interface for detecting missing values with `isna()` and `notna()`."
- "Notice that both `np.nan` and `None` are treated as missing values in Pandas."
- "Boolean masks generated by `isna()` can be used directly for filtering, just like we saw in the previous session."
- "The `axis` parameter controls whether operations are applied to rows (axis=1) or columns (axis=0, default)."
- "These detection methods are the foundation for all missing data handling - you need to know what's missing before you can handle it."

**Exercise 1: Detecting Missing Values (1 minute)**

Have students execute:
```python
# Create a dataset with missing values
survey_data = {
    'Age': [25, 32, np.nan, 41, 28, np.nan],
    'Income': [65000, np.nan, 72000, 58000, np.nan, 83000],
    'Education': ['Bachelor', 'Master', 'PhD', np.nan, 'Bachelor', 'Master'],
    'Satisfaction': [7, 8, np.nan, 6, 9, np.nan]
}
survey_df = pd.DataFrame(survey_data)
print("Survey DataFrame:")
print(survey_df)

# Tasks:
# 1. Count missing values in each column
missing_per_column = survey_df.isna().sum()
print("\n1. Missing values per column:")
print(missing_per_column)

# 2. Find which rows have at least 2 missing values
missing_count_per_row = survey_df.isna().sum(axis=1)
rows_with_multiple_missing = survey_df[missing_count_per_row >= 2]
print("\n2. Rows with at least 2 missing values:")
print(rows_with_multiple_missing)

# 3. Calculate the percentage of missing values in each column
percent_missing = (survey_df.isna().sum() / len(survey_df) * 100).round(1)
print("\n3. Percentage of missing values per column:")
print(percent_missing)
```

**Expected Learning Outcome:** Students should understand how to detect and quantify missing values in a DataFrame, and how to use these methods to filter data based on missing/non-missing status.

---

### 2. Filling Missing Values (5 minutes)

**Slide 3: Strategies for Filling Missing Data**

| Method | Purpose | Common Parameters |
|--------|---------|-------------------|
| `fillna()` | Replace missing values | `value`, `method`, `inplace` |
| `interpolate()` | Fill by interpolation | `method`, `limit`, `inplace` |
| `replace()` | Replace values (including non-NaN) | `to_replace`, `value` |
| `bfill()` / `backfill()` | Fill from next valid value | - |
| `ffill()` / `pad()` | Fill from previous valid value | - |

**Code Example 3: Basic Fill Methods**
```python
# Create a clean copy of our original DataFrame
df = pd.DataFrame(data)
print("Original DataFrame:")
print(df)

# 1. Fill all missing values with a single value
df_filled = df.fillna(0)
print("\n1. Fill all missing values with 0:")
print(df_filled)

# 2. Fill with different values for each column
fill_values = {'A': 0, 'B': -1, 'C': 999, 'D': 0, 'E': 'missing'}
df_custom_fill = df.fillna(fill_values)
print("\n2. Fill with custom values per column:")
print(df_custom_fill)

# 3. Forward fill (propagate last valid observation forward)
df_ffill = df.ffill()
print("\n3. Forward fill (ffill):")
print(df_ffill)

# 4. Backward fill (use next valid observation)
df_bfill = df.bfill()
print("\n4. Backward fill (bfill):")
print(df_bfill)

# 5. Fill with column means (for numeric columns)
df_mean = df.copy()
for col in ['A', 'B', 'C', 'D']:
    df_mean[col] = df_mean[col].fillna(df_mean[col].mean())
print("\n5. Fill numeric columns with their means:")
print(df_mean)
```

**Code Example 4: Interpolation and Advanced Filling**
```python
# Create a sample DataFrame with a clear pattern
ts_data = {
    'Time': pd.date_range(start='2023-01-01', periods=10, freq='D'),
    'Value': [10, 12, np.nan, np.nan, 20, 22, np.nan, 30, np.nan, 36]
}
ts_df = pd.DataFrame(ts_data)
ts_df.set_index('Time', inplace=True)
print("Time series data with missing values:")
print(ts_df)

# 1. Linear interpolation
ts_linear = ts_df.interpolate(method='linear')
print("\n1. Linear interpolation:")
print(ts_linear)

# 2. Different interpolation methods
methods = ['linear', 'quadratic', 'cubic', 'nearest']
print("\n2. Comparing interpolation methods:")
for method in methods:
    try:
        print(f"\n{method.capitalize()} interpolation:")
        print(ts_df.interpolate(method=method))
    except:
        print(f"{method} interpolation requires additional dependencies")

# 3. Limit interpolation to specified number of consecutive NaNs
limited_df = pd.DataFrame({
    'A': [1, np.nan, np.nan, np.nan, 5, 6, np.nan, np.nan, 9]
})
print("\n3a. Original limited_df:")
print(limited_df)

print("\n3b. Interpolation with limit=1:")
print(limited_df.interpolate(limit=1))

# 4. Fill with a function or calculated value
df_calculated = df.copy()
df_calculated['A'] = df_calculated['A'].fillna(df_calculated['A'].median())
df_calculated['B'] = df_calculated['B'].fillna(df_calculated['B'].min())
print("\n4. Fill with calculated values:")
print(df_calculated)
```

**Talking Points:**
- "The choice of fill method should be based on the nature of your data and the analysis you're conducting."
- "For time series data, interpolation methods can recover missing values based on patterns in the data."
- "Forward fill and backward fill are especially useful for time series when you want to carry values forward or backward."
- "Statistical measures like mean, median, or mode are common choices for filling numeric data."
- "Remember that filling is modifying your data - it's important to document your approach and consider its impact on analysis."
- "For categorical data, consider whether a missing value has meaning before deciding how to fill it."

**Exercise 2: Filling Missing Values (1 minute)**

Have students execute:
```python
# Continue with the survey_df from Exercise 1
print("Original survey data:")
print(survey_df)

# Tasks:
# 1. Fill missing Age values with the median age
median_age = survey_df['Age'].median()
survey_filled = survey_df.copy()
survey_filled['Age'] = survey_filled['Age'].fillna(median_age)
print("\n1. After filling Age with median:")
print(survey_filled)

# 2. Fill missing Education values with "Unknown"
survey_filled['Education'] = survey_filled['Education'].fillna("Unknown")
print("\n2. After filling Education with 'Unknown':")
print(survey_filled)

# 3. Fill missing Satisfaction scores using linear interpolation
survey_filled['Satisfaction'] = survey_filled['Satisfaction'].interpolate()
print("\n3. After interpolating Satisfaction:")
print(survey_filled)

# 4. Fill remaining missing values in Income using forward fill
survey_filled['Income'] = survey_filled['Income'].ffill()
print("\n4. After forward filling Income:")
print(survey_filled)
```

**Expected Learning Outcome:** Students should understand various strategies for filling missing values and how to choose the appropriate method based on the data context.

---

### 3. Dropping Missing Data (3 minutes)

**Slide 4: Removing Missing Values**

| Method | Purpose | Key Parameters |
|--------|---------|----------------|
| `dropna()` | Remove rows/columns with missing values | `axis`, `how`, `thresh`, `inplace` |
| `how='any'` | Drop if any missing | Default behavior |
| `how='all'` | Drop only if all missing | Keeps partially complete rows/columns |
| `thresh=n` | Keep if at least n non-NaN values | Fine-grained control |
| `subset=['col1', 'col2']` | Only consider specific columns | Targeted dropping |

**Code Example 5: Dropping Rows and Columns with Missing Values**
```python
# Reset our example
df = pd.DataFrame(data)
print("Original DataFrame:")
print(df)

# 1. Drop rows with any missing values
df_drop_rows = df.dropna()
print("\n1. After dropping rows with any missing values:")
print(df_drop_rows)

# 2. Drop rows where all values are missing
df_drop_all_na = df.dropna(how='all')
print("\n2. After dropping rows where all values are missing:")
print(df_drop_all_na)  # No change in this example as no row has all NaN

# 3. Drop columns with any missing values
df_drop_cols = df.dropna(axis=1)
print("\n3. After dropping columns with any missing values:")
print(df_drop_cols)

# 4. Drop columns where all values are missing
df_drop_all_na_cols = df.dropna(axis=1, how='all')
print("\n4. After dropping columns where all values are missing:")
print(df_drop_all_na_cols)

# 5. Keep rows with at least 3 non-NaN values
df_thresh = df.dropna(thresh=3)
print("\n5. Keep rows with at least 3 non-NaN values:")
print(df_thresh)

# 6. Drop rows with missing values in specific columns
df_subset = df.dropna(subset=['A', 'C'])
print("\n6. Drop rows with NaN in columns A or C:")
print(df_subset)
```

**Talking Points:**
- "Dropping is the simplest strategy, but it can lead to data loss - use cautiously."
- "The `how` parameter is critical - 'any' is much more restrictive than 'all'."
- "The `thresh` parameter lets you keep rows with a minimum amount of data."
- "The `subset` parameter allows targeted dropping based on specific columns."
- "Dropping is often appropriate when missing values are rare, or when you need a complete dataset for specific analyses."
- "Be aware of potential bias introduced by dropping - if missing data correlates with certain characteristics, dropping can skew results."

**Exercise 3: Dropping Missing Values (1 minute)**

Have students execute:
```python
# Create a dataset with structured missing values
structured_missing = pd.DataFrame({
    'ID': [1, 2, 3, 4, 5, 6, 7, 8],
    'Feature1': [np.nan, 5, 6, np.nan, 8, 9, np.nan, 11],
    'Feature2': [1, np.nan, 3, 4, np.nan, 6, 7, np.nan],
    'Feature3': [10, 20, np.nan, 40, 50, np.nan, 70, 80],
    'Target': [100, 150, 200, np.nan, 300, 350, 400, np.nan]
})
print("Dataset with structured missing values:")
print(structured_missing)

# Tasks:
# 1. Drop rows where Target is missing (often necessary for training)
model_data = structured_missing.dropna(subset=['Target'])
print("\n1. After dropping rows with missing Target:")
print(model_data)

# 2. Of the remaining rows, keep only those with at least 3 non-missing features
complete_enough = model_data.dropna(thresh=4)  # ID + 3 features
print("\n2. Rows with at least 3 non-missing features:")
print(complete_enough)

# 3. Check how many samples we've retained
retention_rate = len(complete_enough) / len(structured_missing) * 100
print(f"\n3. Retained {len(complete_enough)} out of {len(structured_missing)} samples ({retention_rate:.1f}%)")
```

**Expected Learning Outcome:** Students should understand how to use the dropna() method with various parameters to remove rows or columns with missing values based on different criteria.

---

### Takeaway Message (1 minute)

**Slide 5: Key Takeaways for Missing Data Handling**

1. **Detection First:** Always start by understanding the pattern and extent of missing values
2. **Context Matters:** The right strategy depends on why data is missing and what analysis you're doing
3. **Multiple Approaches:** Consider combining strategies for different columns based on their characteristics
4. **Document Choices:** Always document how you handled missing data as it affects results
5. **Balance:** Seek a balance between data integrity and completeness

**Slide 6: Decision Flowchart for Missing Data**

```
Start → Is data Missing Completely At Random (MCAR)? 
  → Yes → Less than 5% missing? → Yes → Dropping may be safe
  → No → Missing Not At Random (MNAR)? 
     → Yes → Filling/imputation may introduce bias
     → No → Consider domain-specific strategies
```

**Closing Remarks:**
"Handling missing data is both an art and a science. The methods we've learned today form the foundation of missing data strategies, but remember that domain knowledge is crucial in deciding the best approach. In the next session, we'll explore merging DataFrames, which will allow us to combine data from different sources. Let's take a 5-minute break before continuing."
