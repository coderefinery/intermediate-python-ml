# DataFrame Manipulation & Sorting

## Introduction

**DataFrame Manipulation & Sorting:**

* Now that we can import data, we need to reshape it for analysis
* Most real-world datasets need significant manipulation before analysis
* Selecting, adding, removing, and reordering data are fundamental skills
* These operations build directly on our understanding of DataFrames as labeled, 2D structures

:::{discussion}

* In real-world data analysis, you'll spend about 80% of your time cleaning and manipulating data, and only 20% on actual analysis
* The skills we're covering today form the backbone of data wrangling in Python
* Think of these operations as transforming raw data into analysis-ready information

:::

## Column and Row Selection

**Different Ways to Select Data:**

| Selection Type | Purpose | Example Syntax |
|----------------|---------|----------------|
| Single column | Get one variable | `df['column_name']` or `df.column_name` |
| Multiple columns | Get specific variables | `df[['col1', 'col2']]` |
| Row by index | Get specific observation | `df.loc['index_label']` |
| Row by position | Get nth observation | `df.iloc[n]` |
| Row and column | Get specific value(s) | `df.loc['index', 'column']` |
| Slicing | Get ranges of data | `df.loc['idx1':'idx2', 'col1':'col2']` |

### Basic Selection

:::{demo}

```python
import pandas as pd
import numpy as np

# Create a sample dataset
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],
    'Age': [24, 30, 35, 42, 28],
    'City': ['New York', 'Boston', 'Chicago', 'Seattle', 'Miami'],
    'Salary': [65000, 72000, 85000, 92000, 70000],
    'Department': ['HR', 'Sales', 'Tech', 'Tech', 'Finance']
}
df = pd.DataFrame(data)
df.index = ['emp001', 'emp002', 'emp003', 'emp004', 'emp005']  # Custom index
print("Original DataFrame:")
print(df)

# Single column selection - two methods
print("\n1. Single column as Series:")
print(df['Age'])  # Returns a Series

print("\n2. Alternative syntax for columns without spaces:")
print(df.Age)  # Also returns a Series, but only works if column name has no spaces

# Multiple column selection
print("\n3. Selecting multiple columns:")
print(df[['Name', 'Salary']])  # Returns a DataFrame

# Row selection by index label using .loc
print("\n4. Selecting row by index label:")
print(df.loc['emp003'])  # Returns a Series representing the row

# Row selection by position using .iloc
print("\n5. Selecting row by position (third row):")
print(df.iloc[2])  # Also returns a Series

# Selecting a subset of rows
print("\n6. Selecting multiple rows by position:")
print(df.iloc[1:4])  # Rows 1, 2, and 3 (not including 4)

# Selecting specific cells
print("\n7. Selecting specific value (cell):")
print(df.loc['emp002', 'Salary'])  # Returns the value (72000)

# Selecting a subset of rows and columns
print("\n8. Selecting subset of rows and columns:")
print(df.loc['emp001':'emp003', ['Name', 'Age', 'Salary']])
```

Output

```none
Original DataFrame:
           Name  Age      City  Salary Department
emp001    Alice   24  New York   65000         HR
emp002      Bob   30    Boston   72000      Sales
emp003  Charlie   35   Chicago   85000       Tech
emp004    David   42   Seattle   92000       Tech
emp005      Eva   28     Miami   70000    Finance

1. Single column as Series:
emp001    24
emp002    30
emp003    35
emp004    42
emp005    28
Name: Age, dtype: int64

2. Alternative syntax for columns without spaces:
emp001    24
emp002    30
emp003    35
emp004    42
emp005    28
Name: Age, dtype: int64

3. Selecting multiple columns:
           Name  Salary
emp001    Alice   65000
emp002      Bob   72000
emp003  Charlie   85000
emp004    David   92000
emp005      Eva   70000

4. Selecting row by index label:
Name          Charlie
Age                35
City          Chicago
Salary          85000
Department       Tech
Name: emp003, dtype: object

5. Selecting row by position (third row):
Name          Charlie
Age                35
City          Chicago
Salary          85000
Department       Tech
Name: emp003, dtype: object

6. Selecting multiple rows by position:
           Name  Age     City  Salary Department
emp002      Bob   30   Boston   72000      Sales
emp003  Charlie   35  Chicago   85000       Tech
emp004    David   42  Seattle   92000       Tech

7. Selecting specific value (cell):
72000

8. Selecting subset of rows and columns:
           Name  Age  Salary
emp001    Alice   24   65000
emp002      Bob   30   72000
emp003  Charlie   35   85000
```

:::

### Advanced Selection with Conditions

:::{demo}

```python
# Boolean selection - rows where Age > 30
print("\n9. Boolean selection - employees over 30:")
print(df[df['Age'] > 30])

# Multiple conditions using & (and) and | (or)
print("\n10. Multiple conditions - Tech department with salary > 80000:")
print(df[(df['Department'] == 'Tech') & (df['Salary'] > 80000)])

# Using .query() method for cleaner syntax
print("\n11. Using query method - same condition:")
print(df.query("Department == 'Tech' and Salary > 80000"))

# Row selection with .isin()
print("\n12. Using .isin() - employees in HR or Finance:")
print(df[df['Department'].isin(['HR', 'Finance'])])
```

Output

```none
9. Boolean selection - employees over 30:
           Name  Age     City  Salary Department
emp003  Charlie   35  Chicago   85000       Tech
emp004    David   42  Seattle   92000       Tech

10. Multiple conditions - Tech department with salary > 80000:
           Name  Age     City  Salary Department
emp003  Charlie   35  Chicago   85000       Tech
emp004    David   42  Seattle   92000       Tech

11. Using query method - same condition:
           Name  Age     City  Salary Department
emp003  Charlie   35  Chicago   85000       Tech
emp004    David   42  Seattle   92000       Tech

12. Using .isin() - employees in HR or Finance:
         Name  Age      City  Salary Department
emp001  Alice   24  New York   65000         HR
emp005    Eva   28     Miami   70000    Finance
```

:::

:::{discussion}

* Notice that selecting a single column returns a Series, while selecting multiple columns maintains the DataFrame structure
* The `.loc` accessor is used for label-based indexing, while `.iloc` is for position-based indexing
* Boolean selection is incredibly powerful - it lets you filter data based on specific conditions
* These selection methods can be combined in powerful ways to extract exactly the data you need

:::

:::{exercise}

**Selection Practice:**

Use `inventory` dataframe and

* Select just the Product_Name and Price columns
* Select all products that are in stock (In_Stock is True)
* Select all electronics that cost less than 500
* Select the 2nd and 3rd products using position-based indexing 

```python
# Create a dataset of product inventory
products = {
    'Product_ID': ['P001', 'P002', 'P003', 'P004', 'P005', 'P006'],
    'Product_Name': ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse'],
    'Category': ['Electronics', 'Electronics', 'Electronics', 
                 'Electronics', 'Accessories', 'Accessories'],
    'Price': [1200, 800, 350, 250, 75, 25],
    'In_Stock': [True, True, False, True, True, False],
    'Units': [15, 28, 0, 10, 45, 0]
}
inventory = pd.DataFrame(products)
```

:::

:::{solution}

```python
# Tasks:
# 1. Select just the Product_Name and Price columns
names_prices = inventory[['Product_Name', 'Price']]
print("Product names and prices:")
print(names_prices)

# 2. Select all products that are in stock (In_Stock is True)
in_stock = inventory[inventory['In_Stock'] == True]
print("\nProducts in stock:")
print(in_stock)

# 3. Select all electronics that cost less than 500
cheap_electronics = inventory[(inventory['Category'] == 'Electronics') & 
                              (inventory['Price'] < 500)]
print("\nAffordable electronics:")
print(cheap_electronics)

# 4. Select the 2nd and 3rd products using position-based indexing
second_third = inventory.iloc[1:3]
print("\nSecond and third products:")
print(second_third)
```

Understand the different ways to select data from a DataFrame, including column selection, row selection by label and position, boolean filtering, and combinations of these methods

:::

## Adding and Removing Columns/Rows

**Modifying DataFrame Structure:**

| Operation | Method | Example |
|-----------|--------|---------|
| Add column | Direct assignment | `df['new_col'] = values` |
| Add column | From existing columns | `df['new_col'] = df['col1'] + df['col2']` |
| Add column | Using apply/lambda | `df['new_col'] = df.apply(lambda x: func(x), axis=1)` |
| Remove column | Using drop | `df.drop('column', axis=1)` |
| Remove row | Using drop | `df.drop('index_label')` |
| Add row | Using loc | `df.loc['new_index'] = values` |
| Add row | Using append/concat | `pd.concat([df, new_row])` |

### Adding and Removing Columns

:::{done}

```python

# Create a sample dataset
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],
    'Age': [24, 30, 35, 42, 28],
    'City': ['New York', 'Boston', 'Chicago', 'Seattle', 'Miami'],
    'Salary': [65000, 72000, 85000, 92000, 70000],
    'Department': ['HR', 'Sales', 'Tech', 'Tech', 'Finance']
}
df = pd.DataFrame(data)
df.index = ['emp001', 'emp002', 'emp003', 'emp004', 'emp005']  # Custom index
print("Original DataFrame:")
print(df)

# Continuing with our employee DataFrame
print("Original DataFrame:")
print(df)

# 1. Adding a new column with scalar value
df['Active'] = True
print("\n1. Adding 'Active' column with same value for all rows:")
print(df)

# 2. Adding a column with a list of values
df['Performance'] = [4.5, 4.0, 3.8, 4.7, 4.2]
print("\n2. Adding 'Performance' column with different values:")
print(df)

# 3. Adding a calculated column
df['Bonus'] = df['Salary'] * df['Performance'] / 100
print("\n3. Adding calculated 'Bonus' column:")
print(df)

# 4. Adding a column with conditional values
df['Experience'] = np.where(df['Age'] > 30, 'Senior', 'Junior')
print("\n4. Adding conditional 'Experience' column:")
print(df)

# 5. Removing a single column
df_no_city = df.drop('City', axis=1)
print("\n5. Removing 'City' column:")
print(df_no_city)

# 6. Removing multiple columns
df_minimal = df.drop(['Active', 'Performance', 'Bonus'], axis=1)
print("\n6. Removing multiple columns:")
print(df_minimal)

# 7. Remove columns in-place
# df.drop(['City', 'Active'], axis=1, inplace=True)
```

:::

### Adding and Removing Rows

:::{demo}

```python
# 1. Removing a row by index label
df_no_bob = df.drop('emp002')
print("\n1. DataFrame without Bob (emp002):")
print(df_no_bob)

# 2. Removing multiple rows
df_reduced = df.drop(['emp001', 'emp005'])
print("\n2. DataFrame without emp001 and emp005:")
print(df_reduced)

# 3. Adding a new row with .loc
# Create a copy to avoid SettingWithCopyWarning
df_new = df.copy()
df_new.loc['emp006'] = ['Frank', 38, 'Dallas', 88000, 'Sales', True, 4.1, 3608, 'Senior']
print("\n3. DataFrame with new employee:")
print(df_new)

# 4. Adding a row with a Series
new_employee = pd.Series({
    'Name': 'Grace', 'Age': 27, 'City': 'Denver', 'Salary': 67000, 
    'Department': 'HR', 'Active': True, 'Performance': 4.3,
    'Bonus': 2881, 'Experience': 'Junior'
}, name='emp007')

df_newer = pd.concat([df_new, pd.DataFrame([new_employee])])
print("\n4. DataFrame with another new employee:")
print(df_newer)
```

:::

:::{discussion}

* Adding columns is a common operation, especially when you need to create derived fields or features
* Notice that we can add columns based on calculations from other columns - this is ideal for metrics and KPIs
* The `drop()` function is powerful but doesn't modify the original DataFrame unless you specify `inplace=True`
* Adding rows is less common but useful for simulation, testing, or creating summary rows
* Always be careful with the `axis` parameter - `axis=0` is for rows, `axis=1` is for columns

:::

:::{exercise}

**Adding and Removing Data:**

```python
products = {
    'Product_ID': ['P001', 'P002', 'P003', 'P004', 'P005', 'P006'],
    'Product_Name': ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse'],
    'Category': ['Electronics', 'Electronics', 'Electronics', 
                 'Electronics', 'Accessories', 'Accessories'],
    'Price': [1200, 800, 350, 250, 75, 25],
    'In_Stock': [True, True, False, True, True, False],
    'Units': [15, 28, 0, 10, 45, 0]
}
inventory = pd.DataFrame(products)
```

Use inventory dataframe and

* Add a 'Value' column that multiplies Price by Units
* Add a 'Status' column: 'Available' if In_Stock is True, 'Out of Stock' otherwise
* Remove the In_Stock column (now redundant with Status)
* Add a `new_product` row

```python
new_product = pd.Series({
    'Product_ID': 'P007',
    'Product_Name': 'Headphones',
    'Category': 'Accessories',
    'Price': 150,
    'Units': 20,
    'Value': 3000,
    'Status': 'Available'
})
```

:::

:::{solution}

```python
# Continue with the inventory DataFrame from Exercise 1
print("Original inventory:")
print(inventory)

# 1. Add a 'Value' column that multiplies Price by Units
inventory['Value'] = inventory['Price'] * inventory['Units']
print("\nInventory with Value column:")
print(inventory)

# 2. Add a 'Status' column: 'Available' if In_Stock is True, 'Out of Stock' otherwise
inventory['Status'] = inventory['In_Stock'].map({True: 'Available', False: 'Out of Stock'})
print("\nInventory with Status column:")
print(inventory)

# 3. Remove the In_Stock column (now redundant with Status)
inventory_updated = inventory.drop('In_Stock', axis=1)
print("\nInventory without In_Stock column:")
print(inventory_updated)

# 4. Add a new product row
inventory_final = pd.concat([inventory_updated, pd.DataFrame([new_product])])
print("\nInventory with new product:")
print(inventory_final)
```

:::


### DataFrame Sorting (5 minutes)

**Slide 4: Sorting Data**

| Method | Description | Key Parameters |
|--------|-------------|----------------|
| `sort_values()` | Sort by column values | `by`, `ascending`, `inplace`, `na_position` |
| `sort_index()` | Sort by index | `ascending`, `inplace` |
| Multi-column sorting | Sort by multiple columns | `by=['col1', 'col2']` |
| Custom sorting | Sort with custom orders | `by=col, key=function` |

**Code Example 5: Basic Sorting**
```python
# Continuing with our employee DataFrame
print("Original DataFrame:")
print(df)

# 1. Sorting by a single column (ascending by default)
df_by_age = df.sort_values('Age')
print("\n1. Sorted by Age (ascending):")
print(df_by_age)

# 2. Sorting by a single column (descending)
df_by_salary_desc = df.sort_values('Salary', ascending=False)
print("\n2. Sorted by Salary (descending):")
print(df_by_salary_desc)

# 3. Sorting by index
df_by_index = df.sort_index()
print("\n3. Sorted by index:")
print(df_by_index)

# 4. Sorting by multiple columns
df_multi_sort = df.sort_values(['Department', 'Salary'])
print("\n4. Sorted by Department, then by Salary within each department:")
print(df_multi_sort)

# 5. Sorting with different directions for each column
df_complex = df.sort_values(['Department', 'Salary'], 
                          ascending=[True, False])
print("\n5. Sorted by Department (asc), then by Salary (desc) within each department:")
print(df_complex)
```

**Code Example 6: Advanced Sorting**
```python
# 1. Sorting with NaN values
# Create a DataFrame with some missing values
data_with_nan = df.copy()
data_with_nan.loc['emp001', 'Performance'] = np.nan
data_with_nan.loc['emp003', 'Performance'] = np.nan

print("1. DataFrame with NaN values:")
print(data_with_nan)

# Sort with NaNs at the beginning
print("\n1a. Sorted with NaNs first:")
print(data_with_nan.sort_values('Performance', na_position='first'))

# Sort with NaNs at the end
print("\n1b. Sorted with NaNs last:")
print(data_with_nan.sort_values('Performance', na_position='last'))

# 2. Custom sorting using a key function (Python 3.7+)
# Sort by name length
print("\n2. Custom sorting by name length:")
print(df.sort_values('Name', key=lambda x: x.str.len()))

# 3. Custom categorical sorting
# Create a custom order for departments
dept_order = ['HR', 'Sales', 'Finance', 'Tech']
df['Dept_Coded'] = pd.Categorical(df['Department'], 
                                 categories=dept_order, 
                                 ordered=True)

print("\n3. Custom department order sorting:")
print(df.sort_values('Dept_Coded'))
```

**Talking Points:**
- "Sorting is essential for both data analysis and presentation."
- "Multi-column sorting is particularly useful for hierarchical data."
- "The `ascending` parameter can be a single boolean or a list of booleans for multi-column sorts."
- "Custom sorting allows for domain-specific ordering beyond simple alphabetical or numerical order."
- "The `inplace=True` parameter can be used to modify the original DataFrame rather than creating a new one."

**Exercise 3: Sorting Practice (2 minutes)**

Have students execute:
```python
# Continue with the final inventory DataFrame from Exercise 2
print("Original inventory:")
print(inventory_final)

# 1. Sort the inventory by Category, then by Price (descending) within each category
sorted_by_cat_price = inventory_final.sort_values(['Category', 'Price'], 
                                               ascending=[True, False])
print("\n1. Sorted by Category, then by Price (descending):")
print(sorted_by_cat_price)

# 2. Sort the inventory by Value (highest first)
sorted_by_value = inventory_final.sort_values('Value', ascending=False)
print("\n2. Sorted by Total Value (descending):")
print(sorted_by_value)

# 3. Advanced: Create a custom sorting order for Status
# Make 'Available' come before 'Out of Stock'
inventory_final['Status_Coded'] = pd.Categorical(
    inventory_final['Status'],
    categories=['Available', 'Out of Stock'],
    ordered=True
)
sorted_by_status = inventory_final.sort_values('Status_Coded')
print("\n3. Sorted by Status (custom order):")
print(sorted_by_status[['Product_Name', 'Status', 'Status_Coded']])
```

**Expected Learning Outcome:** Students should understand how to sort DataFrames by single or multiple columns, in ascending or descending order, and with custom sorting rules.

---

### 4. Multiple Column Sorting with Custom Orders (4 minutes)

**Slide 5: Custom Sorting Techniques**

| Technique | Use Case | Method |
|-----------|----------|--------|
| Categorical Data | For non-numeric ordering | `pd.Categorical()` |
| Custom Functions | Complex sorting logic | `sort_values(key=func)` |
| Value Mapping | Translating before sorting | `df['col'].map(mapping)` |
| Rank and Order | Ranking within groups | `df.groupby('col')['val'].rank()` |

**Code Example 7: Complex Sorting Scenarios**
```python
# Create a more complex dataset
sales_data = {
    'Product': ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse', 
               'Laptop', 'Smartphone', 'Tablet', 'Laptop'],
    'Quarter': ['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2', 'Q3', 'Q3', 'Q3', 'Q4'],
    'Region': ['East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West'],
    'Sales': [120000, 80000, 35000, 15000, 8000, 2500, 135000, 95000, 40000, 140000]
}
sales_df = pd.DataFrame(sales_data)
print("Sales DataFrame:")
print(sales_df)

# 1. Create correct quarter ordering
quarter_order = ['Q1', 'Q2', 'Q3', 'Q4']
sales_df['Quarter_Sorted'] = pd.Categorical(sales_df['Quarter'], 
                                           categories=quarter_order, 
                                           ordered=True)

# 2. Create product category with custom order
product_order = ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse']
sales_df['Product_Sorted'] = pd.Categorical(sales_df['Product'], 
                                           categories=product_order, 
                                           ordered=True)

# 3. Sort by Quarter (chronological), then by Product (custom order)
print("\n1. Sorted by Quarter, then by Product (custom orders):")
sorted_sales = sales_df.sort_values(['Quarter_Sorted', 'Product_Sorted'])
print(sorted_sales[['Quarter', 'Product', 'Sales']])

# 4. Sort by Sales volume within each Quarter
print("\n2. Sorted by Quarter, then by Sales (descending) within each quarter:")
sales_by_quarter = sales_df.sort_values(['Quarter_Sorted', 'Sales'], 
                                       ascending=[True, False])
print(sales_by_quarter[['Quarter', 'Product', 'Sales']])

# 5. Rank products by sales within each quarter
sales_df['SalesRank'] = sales_df.groupby('Quarter')['Sales'].rank(ascending=False)
print("\n3. Products ranked by Sales within each Quarter:")
print(sales_df.sort_values(['Quarter_Sorted', 'SalesRank'])[['Quarter', 'Product', 'Sales', 'SalesRank']])
```

**Talking Points:**
- "Custom sorting is essential for business data where natural order exists (days of week, months, quarters)."
- "The `pd.Categorical` type gives you precise control over how categories are ordered."
- "Combining ranking with sorting can create powerful insights about relative performance."
- "These techniques are invaluable for creating executive dashboards or reports with meaningful ordering."

**Exercise 4: Complex Sorting (1 minute)**

Have students execute:
```python
# Create a dataset of monthly sales
monthly_data = {
    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jan', 'Feb', 'Mar', 'Apr', 'May'],
    'Product': ['Widget', 'Widget', 'Widget', 'Widget', 'Widget', 
               'Gadget', 'Gadget', 'Gadget', 'Gadget', 'Gadget'],
    'Sales': [45, 50, 35, 55, 60, 30, 40, 45, 35, 25]
}
monthly_df = pd.DataFrame(monthly_data)

# 1. Create correct month ordering
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
monthly_df['Month_Sorted'] = pd.Categorical(monthly_df['Month'], 
                                          categories=month_order, 
                                          ordered=True)

# 2. Sort by Product, then by Month (chronological)
sorted_monthly = monthly_df.sort_values(['Product', 'Month_Sorted'])
print("Sorted by Product, then chronologically by Month:")
print(sorted_monthly[['Product', 'Month', 'Sales']])

# 3. Find the best month for each product
best_months = monthly_df.loc[monthly_df.groupby('Product')['Sales'].idxmax()]
print("\nBest month for each product:")
print(best_months[['Product', 'Month', 'Sales']])
```

**Expected Learning Outcome:** Students should understand how to implement custom sorting orders, particularly for categorical data like quarters or months, and how to combine sorting with other operations like grouping and ranking.

---

### Takeaway Message (1 minute)

**Slide 6: Key Takeaways**

1. **Flexible Selection:** Pandas provides multiple ways to select, filter, and extract data
2. **Structure Modification:** Adding and removing columns/rows enables dataset evolution
3. **Meaningful Sorting:** Proper sorting is essential for analysis and presentation
4. **Custom Orders:** Categorical data types allow you to enforce domain-specific ordering
5. **Combined Operations:** The real power comes from combining these techniques

**Closing Remarks:**
"The manipulation skills we've learned today form the cornerstone of data wrangling in Pandas. In the next session, we'll build on these skills to explore more advanced indexing and selection techniques, which will give you even more precise control over your data. Take a 5-minute break, and think about how you might apply these techniques to your own datasets."
