# Indexing, Selection & Slicing in Pandas (20 mins)
## Lecture Materials with Exercises

### Introduction (2 minutes)

**Slide 1: Advanced Data Access in Pandas**
- Building on basic selection techniques from previous session
- Precise data access is the foundation of efficient data analysis
- Pandas offers multiple ways to access data, each with specific use cases
- Connecting to NumPy indexing concepts you already know

**Talking Points:**
- "In the previous session, we introduced some basic ways to select data. Now we'll dive deeper into Pandas' powerful indexing systems."
- "Think of these techniques as the surgical tools that let you precisely extract exactly the data you need."
- "Understanding the differences between these indexing methods will make your code more efficient and help you avoid common errors."
- "These concepts build directly on your NumPy knowledge, but with added capabilities for labeled data."

---

### 1. Label vs. Position-based Indexing (6 minutes)

**Slide 2: Two Fundamental Indexing Approaches**

| Indexing Type | Method | Use Case | NumPy Equivalent |
|---------------|--------|----------|------------------|
| Label-based | `.loc[]` | When you know the labels | N/A (NumPy is position-based) |
| Position-based | `.iloc[]` | When you know the positions | Standard NumPy indexing |
| Mixed | Direct `[]` | Simple selection (but less explicit) | N/A |

**Code Example 1: Creating a DataFrame with Meaningful Indices**
```python
import pandas as pd
import numpy as np

# Create a DataFrame with custom indices
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],
    'Department': ['HR', 'Engineering', 'Sales', 'Management', 'Engineering'],
    'Salary': [75000, 85000, 62000, 95000, 78000],
    'Hire_Date': ['2019-05-10', '2018-03-25', '2020-11-15', '2017-08-01', '2020-07-12'],
    'Performance': [4.2, 4.5, 3.9, 4.7, 4.1]
}
df = pd.DataFrame(data)

# Set a meaningful index from an existing column
df.set_index('Name', inplace=True)
print("DataFrame with 'Name' as index:")
print(df)

# Reset index to return to default integer indexing
df_reset = df.reset_index()
print("\nDataFrame with default integer index:")
print(df_reset)
```

**Code Example 2: Label vs. Position-based Indexing**
```python
# 1. Label-based indexing with .loc
print("\n1. Label-based selection (.loc):")
print("Data for 'Bob':")
print(df.loc['Bob'])

# Select multiple rows by label
print("\nData for 'Alice' and 'Eva':")
print(df.loc[['Alice', 'Eva']])

# Select rows and columns by label
print("\nDepartment and Salary for 'Charlie' and 'David':")
print(df.loc[['Charlie', 'David'], ['Department', 'Salary']])

# 2. Position-based indexing with .iloc
print("\n2. Position-based selection (.iloc):")
print("Third row (index position 2):")
print(df.iloc[2])

# Select multiple rows by position
print("\nFirst and fourth rows (positions 0 and 3):")
print(df.iloc[[0, 3]])

# Select rows and columns by position
print("\nRows 1-3, columns 0-1:")
print(df.iloc[1:4, 0:2])

# 3. Mixed indexing (direct [])
print("\n3. Direct indexing []:")
print("'Salary' column:")
print(df['Salary'])

# Mixing approaches (not recommended but sometimes seen)
# print("\nFirst two rows of 'Department' column:")
# print(df['Department'][0:2])  # Chained indexing - can lead to issues
```

**Code Example 3: When to Use Each Approach**
```python
# When dealing with missing values, .loc is safer than direct []
sample_df = df.copy()
print("Original df:")
print(sample_df)

# Add a row with missing values
sample_df.loc['Frank'] = [np.nan, 70000, '2021-01-15', 3.8]
print("\nWith added row 'Frank':")
print(sample_df)

# Try to filter with direct indexing vs .loc
try:
    # This might raise an error if the department column has NaN values
    print("\nDirect filtering on missing data:")
    print(sample_df[sample_df['Department'] == 'Engineering'])
except Exception as e:
    print(f"Error: {e}")

# .loc handles this correctly
print("\nFiltering with .loc:")
print(sample_df.loc[sample_df['Department'] == 'Engineering'])
```

**Talking Points:**
- "The key distinction is that `.loc` uses labels, while `.iloc` uses integer positions."
- "Think of `.loc` as looking up data in a dictionary by key, and `.iloc` as accessing a list by position."
- "Label-based indexing is more intuitive when working with real-world data that has meaningful labels."
- "Position-based indexing connects directly to your NumPy knowledge and is useful for algorithms that need specific positions."
- "Using the direct `[]` approach is convenient but can be ambiguous and lead to unexpected behavior."
- "When filtering data with conditions, particularly with missing values, `.loc` is generally safer."

**Exercise 1: Label vs. Position Indexing (2 minutes)**

Have students execute:
```python
# Create a DataFrame of country data
countries = pd.DataFrame({
    'Population': [331002651, 1380004385, 220892340, 67886011, 37742154],
    'Area_km2': [9833517, 3287263, 881912, 243610, 9984670],
    'GDP_Trillion': [21.43, 14.34, 0.304, 2.71, 1.71]
}, index=['USA', 'China', 'Pakistan', 'UK', 'Canada'])

print("Countries DataFrame:")
print(countries)

# Tasks:
# 1. Use .loc to get the data for China and Canada
print("\n1. Data for China and Canada using .loc:")
print(countries.loc[['China', 'Canada']])

# 2. Use .iloc to get the first and last rows
print("\n2. First and last rows using .iloc:")
print(countries.iloc[[0, -1]])

# 3. Use .loc to get the Area_km2 for UK and Pakistan
print("\n3. Area of UK and Pakistan using .loc:")
print(countries.loc[['UK', 'Pakistan'], 'Area_km2'])

# 4. Use .iloc to get the GDP_Trillion values for the 2nd and 3rd countries
print("\n4. GDP of 2nd and 3rd countries using .iloc:")
print(countries.iloc[1:3, 2])
```

**Expected Learning Outcome:** Students should understand the conceptual difference between label-based and position-based indexing and when to use each approach.

---

### 2. Boolean Indexing (5 minutes)

**Slide 3: Boolean Indexing and Filtering**

| Concept | Description | Connection to NumPy |
|---------|-------------|---------------------|
| Boolean masks | Arrays of True/False values | Direct equivalent in NumPy |
| Comparison operators | `>, <, ==, !=, >=, <=` | Same as NumPy |
| Compound conditions | Combined with `&, |, ~` | Same as NumPy but requires parentheses |
| `query()` method | SQL-like filtering | Pandas-specific, no NumPy equivalent |

**Code Example 4: Creating and Using Boolean Masks**
```python
# Reset example
df = pd.DataFrame(data)
df.set_index('Name', inplace=True)
print("Original DataFrame:")
print(df)

# 1. Simple boolean mask
high_salary_mask = df['Salary'] > 75000
print("\n1. Boolean mask for high salaries:")
print(high_salary_mask)

# Using the mask to filter rows
print("\nEmployees with high salaries:")
print(df[high_salary_mask])

# 2. Inline boolean indexing
print("\n2. Employees in Engineering department:")
print(df[df['Department'] == 'Engineering'])

# 3. Multiple conditions with & (and), | (or)
print("\n3a. Engineering employees with high performance:")
print(df[(df['Department'] == 'Engineering') & (df['Performance'] > 4.2)])

print("\n3b. Employees with either high salary or high performance:")
print(df[(df['Salary'] > 80000) | (df['Performance'] > 4.5)])

# 4. Using .loc with boolean masks
print("\n4. Using .loc with boolean mask:")
recent_hires = df['Hire_Date'] > '2019-01-01'
print(df.loc[recent_hires, ['Department', 'Performance']])
```

**Code Example 5: Advanced Boolean Indexing Techniques**
```python
# 1. Using query() method for cleaner syntax
print("1. Using query() for Engineering employees with high performance:")
print(df.query("Department == 'Engineering' and Performance > 4.2"))

# 2. String methods with boolean indexing
print("\n2. Departments starting with 'E':")
print(df[df['Department'].str.startswith('E')])

# 3. isin() for multiple value matching
print("\n3. Employees in HR or Management:")
print(df[df['Department'].isin(['HR', 'Management'])])

# 4. Combining with function application
def is_recent_hire(date_str):
    from datetime import datetime
    hire_date = datetime.strptime(date_str, '%Y-%m-%d')
    return hire_date.year >= 2020

print("\n4. Recent hires using a function:")
print(df[df['Hire_Date'].apply(is_recent_hire)])
```

**Talking Points:**
- "Boolean indexing is one of the most powerful features in Pandas and NumPy - it lets you filter data based on conditions."
- "The syntax is very similar to NumPy's boolean masking, which you're already familiar with."
- "Remember that when combining conditions, you need to use `&` for AND and `|` for OR, not the Python keywords 'and' and 'or'."
- "Each condition needs to be wrapped in parentheses when combining them - this is a common source of errors."
- "The `query()` method offers a more readable alternative for complex conditions, especially when you have many of them."
- "You can combine boolean indexing with `.loc` to filter rows and select specific columns in one operation."

**Exercise 2: Boolean Indexing Practice (2 minutes)**

Have students execute:
```python
# Create a DataFrame of student data
students = pd.DataFrame({
    'Name': ['Emma', 'Noah', 'Olivia', 'Liam', 'Ava', 'William', 'Sophia', 'Mason'],
    'Grade': [85, 92, 78, 95, 89, 79, 88, 91],
    'Subject': ['Math', 'Science', 'Math', 'Science', 'Art', 'Math', 'Science', 'Art'],
    'Age': [16, 17, 16, 18, 17, 16, 17, 18]
})

print("Students DataFrame:")
print(students)

# Tasks:
# 1. Find all students who scored 90 or above
high_performers = students[students['Grade'] >= 90]
print("\n1. High performers (90+ grade):")
print(high_performers)

# 2. Find all Math students with grades below 80
struggling_math = students[(students['Subject'] == 'Math') & (students['Grade'] < 80)]
print("\n2. Math students with grades below 80:")
print(struggling_math)

# 3. Find all Science or Art students who are 17 years old
science_art_17 = students[(students['Subject'].isin(['Science', 'Art'])) & (students['Age'] == 17)]
print("\n3. Science or Art students who are 17:")
print(science_art_17)

# 4. Use query() to find students whose names start with 'L' or 'W'
name_filter = students.query("Name.str.startswith('L') or Name.str.startswith('W')")
print("\n4. Students with names starting with 'L' or 'W':")
print(name_filter)
```

**Expected Learning Outcome:** Students should understand how to create and use boolean masks for filtering data, including combining multiple conditions and using the query() method.

---

### 3. .loc, .iloc, and .at Selection Methods (4 minutes)

**Slide 4: Specialized Selection Methods**

| Method | Purpose | Use Case | Performance |
|--------|---------|----------|-------------|
| `.loc[]` | Label-based selection | Slicing, multi-label selection | Good for ranges |
| `.iloc[]` | Position-based selection | Numerical indexing | Good for ranges |
| `.at[]` | Single value by label | Fast scalar lookup | Fastest for single values |
| `.iat[]` | Single value by position | Fast scalar lookup | Fastest for single values |

**Code Example 6: Comparing Selection Methods**
```python
# Reset example
df = pd.DataFrame(data)
df.set_index('Name', inplace=True)
print("Original DataFrame:")
print(df)

# 1. Using .loc for single value (by label)
print("\n1a. Bob's Department using .loc:")
print(df.loc['Bob', 'Department'])

# 2. Using .iloc for single value (by position)
print("\n2a. Value at row 1, column 0 using .iloc:")
print(df.iloc[1, 0])

# 3. Using .at for single value access (fastest)
print("\n3. Bob's Department using .at (fastest):")
print(df.at['Bob', 'Department'])

# 4. Using .iat for position-based single value access
print("\n4. Value at row 1, column 0 using .iat (fastest):")
print(df.iat[1, 0])

# 5. Performance comparison for large DataFrame
import time

# Create a larger DataFrame
large_df = pd.DataFrame(np.random.rand(10000, 100))

# Time comparison
print("\n5. Performance comparison:")

start = time.time()
for _ in range(1000):
    value = large_df.loc[5000, 50]
loc_time = time.time() - start
print(f"loc time: {loc_time:.6f} seconds")

start = time.time()
for _ in range(1000):
    value = large_df.at[5000, 50]
at_time = time.time() - start
print(f"at time: {at_time:.6f} seconds")

print(f".at is approximately {loc_time/at_time:.1f}x faster than .loc for single value access")
```

**Talking Points:**
- "While `.loc` and `.iloc` are versatile, `.at` and `.iat` are optimized for single value lookup."
- "Use `.at` and `.iat` when you need to access individual values repeatedly, such as in a loop."
- "The performance difference becomes significant with larger DataFrames."
- "The general rule: Use the most specific tool for the job."
- "For single value access: `.at`/`.iat` > `.loc`/`.iloc` > direct indexing with `[]`."

**Exercise 3: Selection Methods Practice (1 minute)**

Have students execute:
```python
# Use the countries DataFrame from Exercise 1
print("Countries DataFrame:")
print(countries)

# Tasks:
# 1. Use .at to get the GDP of the UK
uk_gdp = countries.at['UK', 'GDP_Trillion']
print(f"\n1. UK GDP using .at: {uk_gdp} trillion USD")

# 2. Use .iat to get the population of the third country
third_population = countries.iat[2, 0]
print(f"\n2. Population of third country using .iat: {third_population}")

# 3. Time comparison between .loc and .at
import time

# Create a new DataFrame
test_df = pd.DataFrame(np.random.rand(1000, 100))

# Using .loc
start = time.time()
for i in range(1000):
    value = test_df.loc[500, 50]
loc_time = time.time() - start

# Using .at
start = time.time()
for i in range(1000):
    value = test_df.at[500, 50]
at_time = time.time() - start

print(f"\n3. Time comparison:")
print(f"   .loc time: {loc_time:.6f} seconds")
print(f"   .at time: {at_time:.6f} seconds")
print(f"   Speed difference: .at is {loc_time/at_time:.1f}x faster")
```

**Expected Learning Outcome:** Students should understand the specialized selection methods `.at` and `.iat` and when to use them for optimized performance.

---

### 4. Multi-level Slicing Techniques (3 minutes)

**Slide 5: Advanced Slicing Techniques**

| Technique | Syntax | Use Case |
|-----------|--------|----------|
| Row range + columns | `.loc[row_start:row_end, cols]` | Extract subset of rows and columns |
| Multiple slices | `.loc[rows, cols]` with slices | Non-continuous ranges |
| Boolean + labels | `.loc[mask, cols]` | Filter rows and select columns |
| Position slicing | `.iloc[row_slice, col_slice]` | Algorithm-driven access |

**Code Example 7: Multi-level Slicing**
```python
# Create a larger DataFrame for demonstration
larger_data = {
    'Region': ['North', 'North', 'North', 'South', 'South', 'East', 'East', 'West', 'West', 'West'],
    'Product': ['A', 'B', 'C', 'A', 'B', 'A', 'C', 'A', 'B', 'C'],
    'Sales': [100, 150, 120, 200, 250, 180, 220, 300, 240, 260],
    'Profit': [20, 35, 25, 40, 50, 35, 45, 60, 48, 52],
    'Returns': [5, 3, 7, 2, 4, 6, 3, 1, 5, 2]
}
sales_df = pd.DataFrame(larger_data)
print("Sales DataFrame:")
print(sales_df)

# 1. Basic row and column slicing with .loc
# First, create an index to use with .loc
sales_df.set_index(['Region', 'Product'], inplace=True)
print("\nSales DataFrame with MultiIndex:")
print(sales_df)

# 2. Selecting rows by partial index match
print("\n1. All 'North' region data:")
print(sales_df.loc['North'])

# 3. Selecting specific rows by full index match
print("\n2. 'South' region, product 'A' data:")
print(sales_df.loc[('South', 'A')])

# 4. Slicing with MultiIndex
print("\n3. From 'North'/'A' to 'South'/'B':")
print(sales_df.loc[('North', 'A'):('South', 'B')])

# 5. Selecting specific rows and columns
print("\n4. Sales and Profit for North region:")
print(sales_df.loc['North', ['Sales', 'Profit']])

# Reset index for position-based examples
sales_df.reset_index(inplace=True)

# 6. Position-based slicing with .iloc
print("\n5. Rows 2-5, columns 2-4:")
print(sales_df.iloc[2:6, 2:5])

# 7. Combining boolean indexing with column selection
high_sales = sales_df['Sales'] > 200
print("\n6. Profit and Returns for high sales rows:")
print(sales_df.loc[high_sales, ['Product', 'Profit', 'Returns']])
```

**Talking Points:**
- "Multi-level slicing gives you precise control over exactly which rows and columns to extract."
- "You can use slices, lists, or boolean arrays for both rows and columns."
- "This is particularly powerful with MultiIndex DataFrames, where you can select data based on hierarchical labels."
- "Combining boolean filtering with column selection is a common pattern in data analysis."
- "These techniques are how you 'zoom in' on exactly the data needed to answer specific questions."

**Exercise 4: Multi-level Slicing Practice (1 minute)**

Have students execute:
```python
# Create a more complex DataFrame
data = {
    'Year': [2020, 2020, 2020, 2021, 2021, 2021, 2022, 2022, 2022],
    'Quarter': ['Q1', 'Q2', 'Q3', 'Q1', 'Q2', 'Q3', 'Q1', 'Q2', 'Q3'],
    'Revenue': [150, 180, 200, 210, 230, 250, 260, 280, 310],
    'Expenses': [120, 140, 160, 170, 190, 200, 220, 240, 260],
    'Customers': [45, 50, 55, 60, 65, 70, 75, 80, 85]
}
financial_df = pd.DataFrame(data)

# Create a MultiIndex
financial_df.set_index(['Year', 'Quarter'], inplace=True)
print("Financial DataFrame with MultiIndex:")
print(financial_df)

# Tasks:
# 1. Select all data for 2021
year_2021 = financial_df.loc[2021]
print("\n1. All data for 2021:")
print(year_2021)

# 2. Select Revenue for 2020-Q2 to 2021-Q1
revenue_subset = financial_df.loc[(2020, 'Q2'):(2021, 'Q1'), 'Revenue']
print("\n2. Revenue from 2020-Q2 to 2021-Q1:")
print(revenue_subset)

# 3. Select Revenue and Expenses for Q3 across all years
q3_data = financial_df.loc[(slice(None), 'Q3'), ['Revenue', 'Expenses']]
print("\n3. Q3 Revenue and Expenses for all years:")
print(q3_data)

# 4. Use .xs for cross-section selection (all Q1 data)
q1_data = financial_df.xs('Q1', level='Quarter')
print("\n4. All Q1 data across years:")
print(q1_data)
```

**Expected Learning Outcome:** Students should understand how to use multi-level slicing to extract precise subsets of data, particularly with MultiIndex DataFrames.

---

### Takeaway Message (1 minute)

**Slide 6: Key Takeaways**

1. **Selection Toolkit:** Different indexing methods are optimized for different tasks
2. **Label vs. Position:** `.loc` uses labels, `.iloc` uses positions - choose based on what you know
3. **Boolean Filtering:** Powerful way to extract data matching specific conditions
4. **Performance Optimization:** Use `.at`/`.iat` for fast single-value access
5. **Multi-level Selection:** Combining techniques gives precise control over data extraction

**Closing Remarks:**
"The indexing and selection techniques we've covered today give you surgical precision to extract exactly the data you need. Remember that `.loc` and `.iloc` are your workhorses for most operations, boolean indexing gives you powerful filtering capabilities, and `.at` and `.iat` provide optimized performance for single value access. In the next session, we'll learn how to handle missing data in Pandas, which is a critical skill for real-world data analysis. Let's take a 10-minute break."